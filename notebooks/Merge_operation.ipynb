{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient, auth\n",
    "from caveclient import chunkedgraph as cg\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pcgv3local.brain-wire-test.org\"\n",
    "global_url = \"https://global.brain-wire-test.org/\"\n",
    "datastack = \"fish1_full\"\n",
    "dataset = \"fish_v241003_test\"\n",
    "resolution = [16, 16, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CAVEclient(datastack_name=datastack, server_address=global_url)\n",
    "cggraph = cg.ChunkedGraphClient(server_address=url, table_name=dataset, auth_client=auth.AuthClient(token=client.auth.token))\n",
    "cv = client.info.segmentation_cloudvolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = \"/root/.cloudvolume/secrets/fish1-pychunkedgraph-google-secret.json\"\n",
    "project_id = \"engert-goog-connectomics\"\n",
    "bucket_name = 'fish1-pychunkedgraph'\n",
    "folder_name = '241003_restore_all_chosenedges_pychunk_dropped_coords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_file_names():\n",
    "    client = storage.Client.from_service_account_json(key_path)\n",
    "    bucket = storage.Bucket(client, bucket_name)\n",
    "    blobs = client.list_blobs(bucket, prefix=folder_name)\n",
    "    # print([blob.name for blob in blobs])\n",
    "    csv_files = [blob.name for blob in blobs if \"edges_0000\" in blob.name.lower()]\n",
    "\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_root_id(x, y, z):\n",
    "    supervoxel_id = cv.download_point(pt=(x, y, z), \n",
    "                                      size=1, \n",
    "                                      agglomerate=False, \n",
    "                                      coord_resolution=resolution)\n",
    "    supervoxel_id = np.int64(supervoxel_id[0, 0, 0, 0]) \n",
    "    root_id = cggraph.get_root_id(supervoxel_id)\n",
    "    # print(root_id, type(root_id))\n",
    "    # latest_root_id = cggraph.get_latest_roots(root_id)\n",
    "    # print(latest_root_id, type(latest_root_id))\n",
    "    \n",
    "    return root_id, supervoxel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from caveclient.base import BaseEncoder, handle_response\n",
    "\n",
    "def custom_do_merge(supervoxels, coords, resolution=(4, 4, 40), params={\n",
    "        \"priority\": False,\n",
    "        \"chebyshev_distance\": 10\n",
    "    }) -> None:\n",
    "    \n",
    "    endpoint_mapping = cggraph.default_url_mapping\n",
    "    url = cggraph._endpoints[\"do_merge\"].format_map(endpoint_mapping)\n",
    "\n",
    "    data = []\n",
    "    for svid, coor in zip(supervoxels, coords):\n",
    "        pos = np.array(coor) * resolution\n",
    "        row = [svid, pos[0], pos[1], pos[2]]\n",
    "        data.append(row)\n",
    "    params = params\n",
    "    response = cggraph.session.post(\n",
    "        url,\n",
    "        data=json.dumps(data, cls=BaseEncoder),\n",
    "        params=params,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = get_bucket_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file_path in enumerate(file_paths):\n",
    "    fs = gcsfs.GCSFileSystem(project=project_id, token=key_path)\n",
    "\n",
    "    with fs.open(f'{bucket_name}/{file_path}', 'rb') as file:\n",
    "        chunks = pd.read_csv(file, chunksize=100)\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            for index, row in chunk.iterrows():\n",
    "                seg1_id, seg2_id, seg1_x, seg1_y, seg1_z, seg2_x, seg2_y, seg2_z = [*row]\n",
    "                seg1_root_id, seg1_supervoxel_id = get_latest_root_id(seg1_x, seg1_y, seg1_z)\n",
    "                seg2_root_id, seg2_supervoxel_id = get_latest_root_id(seg2_x, seg2_y, seg2_z)\n",
    "                print(j, index, seg1_root_id, seg2_root_id)\n",
    "                if seg1_root_id != seg2_root_id:\n",
    "                    try:\n",
    "                        # cggraph.do_merge(supervoxels=[seg1_supervoxel_id, seg2_supervoxel_id], \n",
    "                        #                 coords=np.array([[seg1_x, seg1_y, seg1_z], [seg2_x, seg2_y, seg2_z]]),\n",
    "                        #                 resolution=resolution)\n",
    "                        custom_do_merge(supervoxels=[seg1_supervoxel_id, seg2_supervoxel_id], \n",
    "                                        coords=np.array([[seg1_x, seg1_y, seg1_z], [seg2_x, seg2_y, seg2_z]]),\n",
    "                                        resolution=resolution, \n",
    "                                        params={\n",
    "                                            \"priority\": False,\n",
    "                                            \"chebyshev_distance\": 10\n",
    "                                        })\n",
    "                        print(\"merge\")\n",
    "                        time.sleep(3)\n",
    "                    except Exception as e: \n",
    "\n",
    "                        print(\"error: \", e)\n",
    "                        print(index, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pychunkedgraph.graph import ChunkedGraph\n",
    "cg = ChunkedGraph(graph_id=dataset)\n",
    "cg.client.get_max_operation_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
